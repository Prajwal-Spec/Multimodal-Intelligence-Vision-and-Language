{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be0d22a-c2f2-48d3-a5be-0f9fdfde23e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to c:\\users\\prajwal\\appdata\\local\\temp\\pip-req-build-sinez38p\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting ftfy (from clip==1.0)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from clip==1.0) (23.1)\n",
      "Requirement already satisfied: regex in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from clip==1.0) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from clip==1.0) (4.67.1)\n",
      "Requirement already satisfied: torch in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from clip==1.0) (2.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from clip==1.0) (0.24.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from ftfy->clip==1.0) (0.2.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from torch->clip==1.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from torch->clip==1.0) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from torch->clip==1.0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from torch->clip==1.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from torch->clip==1.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from torch->clip==1.0) (2023.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from torchvision->clip==1.0) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from torchvision->clip==1.0) (10.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from tqdm->clip==1.0) (0.4.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch->clip==1.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\prajwal\\anaconda3\\lib\\site-packages (from jinja2->torch->clip==1.0) (2.1.3)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.8 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 41.0/44.8 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.8/44.8 kB 735.8 kB/s eta 0:00:00\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py): started\n",
      "  Building wheel for clip (setup.py): finished with status 'done'\n",
      "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369571 sha256=0ef875f7f1cef01dde49149c7301adbee5c594677c8aa7d0ad8dc07f78a18d49\n",
      "  Stored in directory: C:\\Users\\prajwal\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-erfxwljj\\wheels\\3f\\7c\\a4\\9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n",
      "Successfully built clip\n",
      "Installing collected packages: ftfy, clip\n",
      "Successfully installed clip-1.0 ftfy-6.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git 'C:\\Users\\prajwal\\AppData\\Local\\Temp\\pip-req-build-sinez38p'\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089f013e-1a04-4bbb-a05b-76929e60732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dcaa7b3-973a-47c8-b77c-5010b43324dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 338M/338M [00:59<00:00, 5.95MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0a472a-085e-498d-b6a5-ad687e34b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "cifar100 = CIFAR100(root=os.path.expanduser(\"~/.cache\"), download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb581abf-9261-4de1-8b84-01cd505a0c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the inputs\n",
    "image, class_id = cifar100[15]\n",
    "image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f02d0f0-264a-4b8a-ab4a-0cba3cbaa8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate features\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image_input)\n",
    "    text_features = model.encode_text(text_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e484e65e-362d-4137-9e8f-d76b590ccb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the top 5 most similliar labels for the image\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "similiarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "values, indices = similiarity[0].topk(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5439584e-f0ec-4469-bfec-33b92c3f5c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Predictions:\n",
      "\n",
      "            lion: 96.339965%\n",
      "           tiger: 1.044002%\n",
      "           camel: 0.284237%\n",
      "      lawn_mower: 0.262529%\n",
      "         leopard: 0.258663%\n"
     ]
    }
   ],
   "source": [
    "# Print the result\n",
    "print(\"\\nTop Predictions:\\n\")\n",
    "for value, index in zip(values, indices):\n",
    "    print(f\"{cifar100.classes[index]:>16s}: {100 * value.item():2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a141e42-0e43-4ac3-b414-6bca80d84876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fa84ed9fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a3fd73d-47ed-4a65-9744-a083d9593f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fdc47-7e83-4bde-8e7e-54db0fa36334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd68e8-d1f7-43ad-aad4-cbd548c1b909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a604b0ee-fd9c-436a-8cc5-87a27c359860",
   "metadata": {},
   "source": [
    "Model: Text encoder follows the architecture of the Original Transformer:\n",
    "\n",
    "base size: 63M-parameter, 12-layer, 768-wide(image), 512-wide model(text) and 8 attention heads. \n",
    "Uses a byte pair encoding(BPE).\n",
    "representation of the text(49,152 size vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1863d8c-ad73-4c59-b25f-7d3ca264bbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple',\n",
       " 'aquarium_fish',\n",
       " 'baby',\n",
       " 'bear',\n",
       " 'beaver',\n",
       " 'bed',\n",
       " 'bee',\n",
       " 'beetle',\n",
       " 'bicycle',\n",
       " 'bottle',\n",
       " 'bowl',\n",
       " 'boy',\n",
       " 'bridge',\n",
       " 'bus',\n",
       " 'butterfly',\n",
       " 'camel',\n",
       " 'can',\n",
       " 'castle',\n",
       " 'caterpillar',\n",
       " 'cattle',\n",
       " 'chair',\n",
       " 'chimpanzee',\n",
       " 'clock',\n",
       " 'cloud',\n",
       " 'cockroach',\n",
       " 'couch',\n",
       " 'crab',\n",
       " 'crocodile',\n",
       " 'cup',\n",
       " 'dinosaur',\n",
       " 'dolphin',\n",
       " 'elephant',\n",
       " 'flatfish',\n",
       " 'forest',\n",
       " 'fox',\n",
       " 'girl',\n",
       " 'hamster',\n",
       " 'house',\n",
       " 'kangaroo',\n",
       " 'keyboard',\n",
       " 'lamp',\n",
       " 'lawn_mower',\n",
       " 'leopard',\n",
       " 'lion',\n",
       " 'lizard',\n",
       " 'lobster',\n",
       " 'man',\n",
       " 'maple_tree',\n",
       " 'motorcycle',\n",
       " 'mountain',\n",
       " 'mouse',\n",
       " 'mushroom',\n",
       " 'oak_tree',\n",
       " 'orange',\n",
       " 'orchid',\n",
       " 'otter',\n",
       " 'palm_tree',\n",
       " 'pear',\n",
       " 'pickup_truck',\n",
       " 'pine_tree',\n",
       " 'plain',\n",
       " 'plate',\n",
       " 'poppy',\n",
       " 'porcupine',\n",
       " 'possum',\n",
       " 'rabbit',\n",
       " 'raccoon',\n",
       " 'ray',\n",
       " 'road',\n",
       " 'rocket',\n",
       " 'rose',\n",
       " 'sea',\n",
       " 'seal',\n",
       " 'shark',\n",
       " 'shrew',\n",
       " 'skunk',\n",
       " 'skyscraper',\n",
       " 'snail',\n",
       " 'snake',\n",
       " 'spider',\n",
       " 'squirrel',\n",
       " 'streetcar',\n",
       " 'sunflower',\n",
       " 'sweet_pepper',\n",
       " 'table',\n",
       " 'tank',\n",
       " 'telephone',\n",
       " 'television',\n",
       " 'tiger',\n",
       " 'tractor',\n",
       " 'train',\n",
       " 'trout',\n",
       " 'tulip',\n",
       " 'turtle',\n",
       " 'wardrobe',\n",
       " 'whale',\n",
       " 'willow_tree',\n",
       " 'wolf',\n",
       " 'woman',\n",
       " 'worm']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar100.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337b3ba0-55bb-4991-a5ab-5f6544c585d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c280f-4eb8-42aa-a58e-8387bcdf9820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fded224-4089-44f3-8c12-df3316ed3424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a335f-6029-4863-a5b3-acea4a15ba5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf060456-3a4f-4298-8222-5f28c29c52d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2b0dd-27fa-422d-8a9c-deae2e521749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c9615-9254-4df0-af71-d0a48cc71821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca03cb2-de62-4fce-b215-3177b7ab80f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0bac3-a6a2-49c7-8d99-c74e44a49a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a703845-913f-42a8-bcb7-2427384a180f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3abba-2b0c-420f-aaf1-85362e0541ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44555f12-cc0d-44cd-8fd3-f501f040c1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6b55a-e7e1-4d3d-9c66-41ad7c6a9390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36332696-0cf3-41f1-9fe9-c008f8634e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a55726-4683-45bb-8bcb-0990a08b1870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e0172-5a25-4892-8e71-7b7f49c087af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
